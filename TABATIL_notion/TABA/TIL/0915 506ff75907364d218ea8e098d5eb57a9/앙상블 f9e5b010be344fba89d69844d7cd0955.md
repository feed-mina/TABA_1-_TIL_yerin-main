# 앙상블

### 결정트리 :이상적인 머신 러닝모델이 되기 히든 한 가지 특징을 갖는다. 바로 부정확성이다.

### 결정트리는 질문과 답으로 이루어졌다. 질문들에 답을 해가면서 한 단계식 내려갈 수 있다. 1) 하나의 시작 시점에서 퍼져나가는 모습이 마치 나무와 비슷하고 2) 그리고 한 단계 내려갈때마다 왼쪽으로 갈지 오른쪽으로 갈지 선택하는 알고리즘이다.

### 지니불순도

머신 러닝 프로그램이 결정트리를 만들때는 경험을 통해 직접 정해나간다. 데이터를 분류해보면서 각 위치에서 어떤 노드가 제일 좋은지 고른다. 

선형 회귀 알고리즘의 목적은 학습데이터를 가장 잘 나타낼 수 있는 일차식을 찾는것 

결정 트리의 목적은 학습데이터를 직접 분류해보면서 데이터를 가장 잘 분류할 수 있는 노드들을 찾는다.

따라서 어떻게 분류하거나 질문을 하는게 좋고 안좋은지에 대한 기준, 전에 배웠던 손실함수 같은 개념이 필요하다. 결정 트리에서는 이 부분을 지니 불순도 , gini inpurity 라고 한다.

### 

### 

### ⇒ 응용하면 성능이 좋은 다른 모델들을 만들 수 있음

### 그 방법의 대표가 바로 앙상블 (ensemble)

여러 독립적인 객체들이 만들어내는 조화로운 단체

하나의 모델을 쓰는 대신 수많은 모델들을 사용해 종합적인 판단을 하는 것

수많은 모델들을 만들고 이 모델들의 예측을 합쳐서 종합적인 예측을 하는 기법

### 랜덤 포레스트

트리 모델들을 임의로 많이 만들어서 다수결 투표로 결과를 종합하는 알고리즘

2가지 임의 요소 ! 

### 1 Bootstrapping: 갖고 있는 데이터셋으로 다른 데이터셋을 만들어내는 방법

임의로 데이터를 갖고와 새로운 데이터에 추가한다.

Bootstrapping 데이터셋

모든 모델을 정확히 똑같은 데이터셋으로 학습시키면 결과 다양성 떨어질 수 있음

이 문제를 예방하기 위해 임의로 만들어준 Bootstrap 데이터셋으로 학습시킨다.

Bootstrap 데이터 셋을 만들어내고 모델들의 결정을 합친다.(aggregating) ⇒ Bagging

### 2 임의로 결정 트리 만들기

결정트리를 그냥 만들때는 각 속성들의 지니불순도를 고른 후 가장 낮은 결과를 초이스한다. 임의로 속성 두개 선택을 한다. 예를 들어 고열과 기침을 사용한다. 두개만 비교해서 노드를 만든다. 

질문 1 고열이 있나요? 

또 임의로 속성 두개 선택을 한다.

트리를 임의로 만들기 때문에 다양한 트리가 만들어질 수 있다.

bootstrapping을 사용해서 임의로 데이터셋을 만든다

결정트리를 만들때 속성을 임의로 고르면서 만든다.

이 과정을 여러 번 반복한다. 이 과정을 임의로 많은 배수를 만드는 과정이 랜덤포레스트라고 한다.

### scikit-learn으로 랜덤 포레스트 쉽게 사용하기

### 

###